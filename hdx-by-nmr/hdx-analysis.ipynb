{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduce NMR HDX Figure\n",
    "\n",
    "Inputs:\n",
    "\n",
    "+ `peak-files/` contains sparky-style peak lists for hA9 and hA9/M63F\n",
    "+ `peak-file-index.xlsx` maps those peak files to their time points\n",
    "+ `structure/` contains a pdb file (`1irj.pdb`) for mapping to structure\n",
    "   and a pymol script (`generate-structure-plots.pml`) for generating the\n",
    "   structure figure. \n",
    "  \n",
    "To generate the figure, run this notebook, and then use pymol to run \n",
    "`generate-structure-plots.pml`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_time_index(excel_file,dir_base):\n",
    "    \"\"\"\n",
    "    Take an excel file with the columns:\n",
    "    \n",
    "    File #: number of file holding peaks at this time point\n",
    "    Protein: protien name for this file\n",
    "    Timepoint (minutes): time point in minutes\n",
    "    \n",
    "    dir_base is directory holding the peaks files. \n",
    "    \n",
    "    Returns dataframe with protein, filename, and time columns\n",
    "    \"\"\"\n",
    "\n",
    "    protein = []\n",
    "    filename = []\n",
    "    time = []\n",
    "\n",
    "    df = pd.read_excel(excel_file)\n",
    "    for i in range(len(df)):\n",
    "        row = df.iloc[i,:]\n",
    "        if np.isnan(row[\"File #\"]):\n",
    "            continue\n",
    "\n",
    "        prot = row[\"Protein\"]\n",
    "\n",
    "        protein.append(prot)\n",
    "        filename.append(os.path.join(dir_base,\n",
    "                                     prot.lower(),\n",
    "                                     \"{:d}.list\".format(int(row['File #']))))\n",
    "        time.append(row[\"Timepoint (minutes)\"])\n",
    "\n",
    "    return pd.DataFrame({\"protein\":protein,\"time\":time,\"filename\":filename})\n",
    "\n",
    "\n",
    "def load_peak_files(df):\n",
    "    \"\"\"\n",
    "    Load peak files corresponding to HSQC vs. time into a single data frame. \n",
    "    df is a dataframe generated by get_file_time_index. \n",
    "    \"\"\"\n",
    "    \n",
    "    final_data = pd.DataFrame()\n",
    "    \n",
    "    n = 0\n",
    "    for i in range(len(df)):\n",
    "        row = df.iloc[i]\n",
    "        \n",
    "        # read in data, get rid of duplicates/empties\n",
    "        data = pd.read_fwf(row.filename)\n",
    "        data = data.drop_duplicates()\n",
    "        data = data.dropna()\n",
    "        data = data.drop(data[data[\"Assignment\"]== \"?-?\"].index)\n",
    "        data = data.drop(data[data[\"Assignment\"]== \"W88NE1-HE1\"].index)        \n",
    "\n",
    "        data = data.reset_index(drop=True)\n",
    "        \n",
    "        # add residue number and timepoint, drop all columns except res # and intensity\n",
    "\n",
    "        x = [i.split(\"N-H\")[0] for i in data.Assignment.values]\n",
    "        x = [int(i[1:]) for i in x]\n",
    "        data[\"residue\"] = x\n",
    "        data[\"time\"] = row.time\n",
    "        data[\"protein\"] = row.protein\n",
    "        data = data.drop([\"Assignment\", \"w1\", \"w2\"], axis=1)\n",
    "        n+=1\n",
    "\n",
    "        final_data = pd.concat([final_data, data])\n",
    "\n",
    "    final_data = final_data.rename(columns={\"Data Height\":\"height\"})\n",
    "        \n",
    "    return final_data\n",
    "\n",
    "def hdx_fitter_aic(input_data,\n",
    "                   try_to_fit_cutoff=1.0,\n",
    "                   slow_cutoff=1.0,\n",
    "                   num_across=9,\n",
    "                   ylim=None,xlim=None,\n",
    "                   colors=[\"black\",\"red\"],\n",
    "                   secondary_colors=[\"gray\",\"pink\"],\n",
    "                   manual_mapping=None,\n",
    "                   plot_zero_points=False):\n",
    "    \"\"\"\n",
    "    Take a data frame holding proteins, residues, times, and heights and then\n",
    "    fit the decay constant for each protein/residue pair.  Generates an array\n",
    "    of subplots, one for each residue.  The behavior of the residue in a each \n",
    "    protein is plotted as a series on the subplot.  The program fits a linear,\n",
    "    exponential, and stretched exponential model to each series, and then \n",
    "    decides which fit is justified using an AIC test.  The zero time point is\n",
    "    not used in the fit. \n",
    "    \n",
    "    input_data: output of load_peak_file.  expected to have colummns with\n",
    "                protein, residue, time, and height\n",
    "    try_to_fit_cutoff: only try to fit a curve where residue has at least one\n",
    "                       peak for t > 0 with height above try_to_fit_cutoff. \n",
    "                       height is given in millionths of intensity, meaning \n",
    "                       try_to_fit_cutoff=1.0 means peaks must be above 1e6.\n",
    "    slow_cutoff: \n",
    "    num_across: how many columns in subplot.  Number of rows will be determined\n",
    "                automatically to accomodate all residues.\n",
    "    xlim, ylim: xlim and ylim (each a 2-length tuple) indicating the limits on\n",
    "                on each subplot\n",
    "    colors: colors for proteins.  proteins will be plotted in alphabetical\n",
    "            order, so the first color in the list will be for the first\n",
    "            alphabetical protein, etc. \n",
    "    secondary_colors: colors for proteins that are assigned as \"fast\" or \"slow\"\n",
    "                      and thus not fit explicitly.\n",
    "    manual_mapping: dictionary with form {protein_name:{residue_number:assign}}\n",
    "                    where \"assign\" is either fast or slow.  This lets the user\n",
    "                    manually specify that a given protein/residue should be \n",
    "                    forced to be fast or slow.  This assumes the fitter found\n",
    "                    the best model for that protein/residue pair was linear, so\n",
    "                    not cheating and calling an exponential fit fast or slow.\n",
    "    plot_zero_points: plot lines indicating position of zero points\n",
    "                    \n",
    "    Returns fig, ax, and dataframe holding fit results. \n",
    "    \"\"\"\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # Local functions for performing fits\n",
    "    \n",
    "    def line(x, b):\n",
    "        return b\n",
    "    \n",
    "    def decay(x, a, k):\n",
    "        return a * np.exp(-k * x)\n",
    "\n",
    "    def decay_stretch(x, a, k, beta):\n",
    "        return a * np.exp(-(k * x)**beta)\n",
    "        \n",
    "    def get_aic(model_vals,Y,k):\n",
    "        \"\"\"\n",
    "        model_vals: model values at points correspodning to Y\n",
    "        Y: Y points\n",
    "        k: number of fit parameters\n",
    "        \n",
    "        AICc due to small sample size:\n",
    "        https://en.wikipedia.org/wiki/Akaike_information_criterion\n",
    "        \"\"\"\n",
    "        \n",
    "        sigma2 = np.std(Y)**2        \n",
    "        lnL = -0.5*(np.sum((Y - model_vals)**2/sigma2 + np.log(sigma2)))\n",
    "        \n",
    "        n = len(Y)\n",
    "\n",
    "        aic = 2*k - 2*lnL\n",
    "        \n",
    "        corr = (2*k**2 + 2*k)/(n - k - 1)\n",
    "\n",
    "        return aic + corr\n",
    "        \n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # Preprocess data frame\n",
    "    \n",
    "    all_data = input_data.copy()\n",
    "    \n",
    "    # Rescale data so time is in seconds and height is in millions of units\n",
    "    all_data[\"time\"] = all_data[\"time\"]*60\n",
    "    all_data[\"height\"] = all_data[\"height\"]/1e6\n",
    "    \n",
    "    # This will hold fractional height relative to the zero time point\n",
    "    all_data[\"fx\"] = all_data[\"height\"]\n",
    "    \n",
    "    # Sorted lists of proteins and residues\n",
    "    proteins = list(all_data.protein.unique())\n",
    "    proteins.sort()\n",
    "    \n",
    "    resid_list = list(all_data.residue.unique())\n",
    "    resid_list.sort()\n",
    "    \n",
    "    # For each protein...\n",
    "    for p in proteins:        \n",
    "        \n",
    "        # Data for that protein\n",
    "        x = all_data[all_data.protein == p]\n",
    "        \n",
    "        # Get min and average height for this protein \n",
    "        min_value = np.nanmin(x[\"fx\"])\n",
    "        avg_zero = np.nanmean(x[x.time == 0].height)\n",
    "        \n",
    "        # For each residue\n",
    "        for r in resid_list:            \n",
    "            \n",
    "            # Data for residue in that protein\n",
    "            y = x[x.residue == r]\n",
    "            \n",
    "            # If such data exists\n",
    "            if len(y) > 0:\n",
    "                \n",
    "                # Get zero point\n",
    "                z = y[y.time == 0]\n",
    "                \n",
    "                # If no zero point for this residue, assign start height\n",
    "                # to the average height at zero\n",
    "                if len(z) > 0:\n",
    "                    start_height = z.height.iloc[0]\n",
    "                else:\n",
    "                    start_height = avg_zero\n",
    "                \n",
    "                # If start height is nan or negative, assign to average\n",
    "                if np.isnan(start_height) or start_height <= 0:\n",
    "                    start_height = avg_zero\n",
    "                \n",
    "                # Mask on all data that matches the protein and residue\n",
    "                mask = np.logical_and(all_data.protein == p,\n",
    "                                      all_data.residue == r)\n",
    "                \n",
    "                # Normalize data to be between zero and one\n",
    "                v = (all_data.loc[mask,\"fx\"] - min_value)/(start_height - min_value)\n",
    "                \n",
    "                # Update main data frame\n",
    "                all_data.loc[mask,\"fx\"] = v\n",
    "    \n",
    "    # Separate zero points from the main data frame\n",
    "    zero_points = all_data[all_data.time == 0]\n",
    "    all_data = all_data[all_data.time != 0]\n",
    "                \n",
    "    # -------------------------------------------------------------------------\n",
    "    # Construct plot object\n",
    "\n",
    "    # Figure out how big to make the plot array\n",
    "    num_resid = len(resid_list)\n",
    "    num_down = num_resid // num_across + int(num_resid % num_across != 0)\n",
    "    \n",
    "    # Create fig and ax array objects\n",
    "    fig, ax = plt.subplots(num_down,num_across,figsize=(8,10.5))\n",
    "    \n",
    "    # Make 1000 point array for drawing smooth lines\n",
    "    x_span = np.linspace(0,np.max(all_data[\"time\"]),1000)\n",
    "\n",
    "    # If xlim is not specified, figure out useful xlim\n",
    "    if xlim is None:\n",
    "    \n",
    "        x_min = np.nanmin(all_data[\"time\"])\n",
    "        x_max = np.nanmax(all_data[\"time\"])\n",
    "        x_offset = (x_max - x_min)*.05\n",
    "        x_min = x_min - x_offset\n",
    "        x_max = x_max - x_offset\n",
    "\n",
    "        xlim = (x_min,x_max)\n",
    "    \n",
    "    # If ylim is not specified, figure out useful ylim\n",
    "    if ylim is None:\n",
    "        y_min = np.nanmin(all_data[\"height\"])\n",
    "        y_max = np.nanmax(all_data[\"height\"])\n",
    "        y_offset = (y_max - y_min)*.15\n",
    "        y_min = y_min - y_offset\n",
    "        y_max = y_max - y_offset\n",
    "        \n",
    "        ylim = (y_min,y_max)\n",
    "    \n",
    "    # Generate plots for each residue\n",
    "    plot_row = 0\n",
    "    plot_column = 0\n",
    "    index = 0 \n",
    "    while True:\n",
    "\n",
    "        # Update counter if we've reached right-most column\n",
    "        if plot_column >= num_across:\n",
    "            plot_column = 0\n",
    "            plot_row += 1\n",
    "\n",
    "        # See if we've run out of subplots\n",
    "        if plot_row >= num_down:\n",
    "            break\n",
    "        if plot_column >= num_down:\n",
    "            break\n",
    "\n",
    "        # ax for appropriate subplot\n",
    "        a = ax[plot_row,plot_column]\n",
    "            \n",
    "        # Set title to residue number\n",
    "        if index < len(resid_list):\n",
    "            a.set_title(resid_list[index])\n",
    "        \n",
    "        # Create pretty axes\n",
    "        a.set_xlim(*xlim)\n",
    "        a.set_ylim(*ylim)\n",
    "        \n",
    "        for s in [\"right\",\"left\",\"top\",\"bottom\"]:\n",
    "            a.spines[s].set_visible(False)\n",
    "        \n",
    "        # For left-most column, add y-axes\n",
    "        if plot_column == 0:\n",
    "            a.spines[\"left\"].set_visible(True)\n",
    "            a.set_ylabel(\"height\")\n",
    "        else:\n",
    "            a.get_yaxis().set_ticks([])\n",
    "        \n",
    "        # For bottom row, add x-axes\n",
    "        if plot_row == num_down - 1:\n",
    "            a.spines[\"bottom\"].set_visible(True)\n",
    "            a.set_xlabel(\"time (s)\")\n",
    "        else:\n",
    "            a.get_xaxis().set_ticks([])\n",
    "        \n",
    "        # Update counters\n",
    "        plot_column += 1\n",
    "        index += 1\n",
    "        \n",
    "    # -------------------------------------------------------------------------\n",
    "    # Do fitting and plotting for each protein and each residues\n",
    "    \n",
    "    # Lists to hold output data for final df\n",
    "    protein = []\n",
    "    rate = []\n",
    "    err = []\n",
    "    residue = []\n",
    "    flag = []\n",
    "    \n",
    "    # Loop over proteins\n",
    "    for index, prot in enumerate(proteins):\n",
    "\n",
    "        # Counters for keeping track of subplot\n",
    "        plot_row = 0\n",
    "        plot_column = 0\n",
    "        \n",
    "        # Grab protein-specific data\n",
    "        data = all_data.loc[all_data[\"protein\"] == prot]\n",
    "        zero_data = zero_points.loc[zero_points[\"protein\"] == prot]\n",
    "        \n",
    "        # For each residue\n",
    "        for i in resid_list:\n",
    "            \n",
    "            # Figure out what subplot we're on\n",
    "            if plot_column >= num_across:\n",
    "                plot_column = 0\n",
    "                plot_row += 1\n",
    "            \n",
    "            # Grab residue-specific data.  If there is no data for this \n",
    "            # residue for this protein, move on without plotting or fitting\n",
    "            df = data.loc[data[\"residue\"] == i]\n",
    "            if len(df) == 0:\n",
    "                plot_column += 1\n",
    "                continue\n",
    "\n",
    "            # Record that we are doing to fit this protein/residue pair\n",
    "            protein.append(prot)\n",
    "            residue.append(i)\n",
    "            \n",
    "            # Grab time, height, and fraction for doing fits\n",
    "            X = np.array(df[\"time\"])\n",
    "            Y = np.array(df[\"height\"])\n",
    "            FX = np.array(df[\"fx\"])\n",
    "            \n",
    "             # Get the zero data frame for this residue\n",
    "            zero_df = zero_data.loc[zero_data[\"residue\"] == i]\n",
    "            \n",
    "            # We're going to fit three models.  Make list to hold aic and model\n",
    "            # name for each fit. \n",
    "            all_aic = []\n",
    "            model_names = []\n",
    "            \n",
    "            # fit line w/ slope = 0\n",
    "            lin_opt, lin_cov = curve_fit(line,X,Y,p0=[Y[0]])\n",
    "            lin_model_vals = line(X, *lin_opt)\n",
    "\n",
    "            all_aic.append(get_aic(lin_model_vals,Y,1))\n",
    "            model_names.append(\"linear\")\n",
    "\n",
    "            # If we have actually have a peak above try_to_fit_cutoff, try exp and stretch\n",
    "            if np.max(Y) > try_to_fit_cutoff:\n",
    "            \n",
    "                # exponential, force positive k\n",
    "                try:\n",
    "                    exp_opt, exp_cov = curve_fit(decay,X,Y,p0=[3,0.02],bounds=([0.5,0],np.inf))\n",
    "                    exp_model_vals = decay(X, *exp_opt)\n",
    "                    all_aic.append(get_aic(exp_model_vals,Y,2))\n",
    "                    model_names.append(\"exponential\")\n",
    "\n",
    "                except RuntimeError:\n",
    "                    pass\n",
    "\n",
    "                # Stretched exponential     \n",
    "                try:\n",
    "\n",
    "                    str_opt, str_cov = curve_fit(decay_stretch,X,Y,p0=[3,0.02,1],\n",
    "                                                 bounds=([0.5,0,0],\n",
    "                                                         [np.inf,np.inf,np.inf]))\n",
    "                    str_model_vals = decay_stretch(X, *str_opt)\n",
    "                    all_aic.append(get_aic(str_model_vals,Y,3))\n",
    "                    model_names.append(\"stretched\")\n",
    "\n",
    "                except RuntimeError:\n",
    "                    pass\n",
    "\n",
    "            # Get the model with the minimum AIC\n",
    "            model = model_names[all_aic.index(min(all_aic))]\n",
    "\n",
    "            # If linear model was best model, record it.  If the mean FX for \n",
    "            # this residue is above slow cutoff, assign it \"slow\" (no exchange).\n",
    "            # Otherwise, assign it \"fast\" (exchange faster than we could\n",
    "            # measure). \n",
    "            if model == \"linear\":\n",
    "                \n",
    "                rate.append(0)\n",
    "                err.append(0)      \n",
    "                if np.mean(FX) > slow_cutoff:\n",
    "                    flag.append(\"slow\")\n",
    "                else:\n",
    "                    flag.append(\"fast\")\n",
    "        \n",
    "                model_values = [line(x_span, *lin_opt) for _ in range(len(x_span))]\n",
    "            \n",
    "            # If exponential was best model, record it\n",
    "            elif model == \"exponential\":\n",
    "                rate.append(exp_opt[1])\n",
    "                err.append(np.sqrt(np.diag(exp_cov))[1])\n",
    "                flag.append(\"exponential\")\n",
    "                model_values = decay(x_span, *exp_opt)\n",
    "            \n",
    "            # If stretched was best model, record it\n",
    "            elif model == \"stretched\":\n",
    "                rate.append(str_opt[1])\n",
    "                err.append(np.sqrt(np.diag(str_cov))[1])\n",
    "                flag.append(\"stretch\")\n",
    "                model_values = decay_stretch(x_span, *str_opt)\n",
    "                \n",
    "            # If we get here, something dreadful happened\n",
    "            else:\n",
    "                err = \"should never get here\\n\"\n",
    "                raise RuntimeError(err)\n",
    "            \n",
    "            # Load manually mapped in calls. \n",
    "            try:\n",
    "                flag[-1] = manual_mapping[prot][i]\n",
    "            except (KeyError,TypeError):\n",
    "                pass\n",
    "            \n",
    "            # Figre out what to do with color in plot\n",
    "            color = colors[index]\n",
    "            if flag[-1] == \"fast\":\n",
    "                color = secondary_colors[index]\n",
    "\n",
    "            # Get subplot we're going to draw on\n",
    "            a = ax[plot_row,plot_column]\n",
    "            \n",
    "            # Plot points and fit, if successful\n",
    "            a.plot(X, Y, \"ok\", color=color, ms=2)\n",
    "            if model_values is not None:\n",
    "                a.plot(x_span,model_values,\"-\",color=color)\n",
    "                \n",
    "            if plot_zero_points:\n",
    "                if len(zero_df) > 0:\n",
    "                    zero_y = zero_df.height.iloc[0]\n",
    "                    a.plot((x_span[0],x_span[-1]),(zero_y,zero_y),'--',color=color)\n",
    "                \n",
    "            # Update subplot counter\n",
    "            plot_column += 1\n",
    "\n",
    "    # Build final results data frame\n",
    "    results = pd.DataFrame({\"protein\":protein,\n",
    "                            \"residue\":residue,\n",
    "                            \"flag\":flag,\n",
    "                            \"rate\":rate,\n",
    "                            \"err\":err})\n",
    "\n",
    "    # Clean up fig\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    return fig, ax, results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and fit exchange data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_mapping = {\"M63F\":{19:\"slow\",\n",
    "                          22:\"slow\",\n",
    "                          40:\"slow\",\n",
    "                          41:\"slow\",\n",
    "                          42:\"slow\",\n",
    "                          66:\"slow\",\n",
    "                          78:\"slow\",\n",
    "                          80:\"fast\",\n",
    "                          82:\"slow\",\n",
    "                          83:\"slow\",\n",
    "                          84:\"fast\"},\n",
    "                  \"A9\":{53:\"fast\",\n",
    "                        79:\"fast\",\n",
    "                        82:\"slow\",\n",
    "                        83:\"slow\"}}\n",
    "\n",
    "for p in [\"A9\",\"M63F\"]:\n",
    "    for i in range(46,62):\n",
    "        manual_mapping[p][i] = \"fast\"\n",
    "    \n",
    "    for i in range(86,114):\n",
    "        manual_mapping[p][i] = \"fast\"\n",
    "\n",
    "all_files = get_file_time_index(\"peak-file-index.xlsx\",\"peak-files/\")\n",
    "peaks = load_peak_files(all_files)\n",
    "fig, ax, exchange_data = hdx_fitter_aic(peaks,manual_mapping=manual_mapping) \n",
    "\n",
    "fig.savefig(\"hdx-fit-plots.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct summary data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residues = list(exchange_data.residue.unique())\n",
    "residues.sort()\n",
    "\n",
    "out = {\"residue\":residues}\n",
    "df = pd.DataFrame(out)\n",
    "df[\"A9_type\"] = None\n",
    "df[\"A9_rate\"] = np.nan\n",
    "df[\"A9_err\"] = np.nan\n",
    "df[\"M63F_type\"] = None\n",
    "df[\"M63F_rate\"] = np.nan\n",
    "df[\"M63F_err\"] = np.nan\n",
    "\n",
    "for i, r in enumerate(residues):\n",
    "    for prot in [\"A9\",\"M63F\"]:\n",
    "        mask = np.logical_and(exchange_data.residue == r,\n",
    "                              exchange_data.protein == prot)\n",
    "        tmp = exchange_data.loc[mask,:]\n",
    "        if len(tmp) > 0:\n",
    "            df[f\"{prot}_type\"].iloc[i] = tmp[\"flag\"].iloc[0]\n",
    "            df[f\"{prot}_rate\"].iloc[i] = tmp[\"rate\"].iloc[0]\n",
    "            df[f\"{prot}_err\"].iloc[i] = tmp[\"err\"].iloc[0]\n",
    "\n",
    "df.to_csv(\"hdx-fit-results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write out results to bfactor column of pdb file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TO_NUMBER = {\"fast\":0,\n",
    "             \"exponential\":1,\n",
    "             \"slow\":2,\n",
    "             (\"fast\",\"fast\"):3,\n",
    "             (\"fast\",\"exponential\"):4,\n",
    "             (\"exponential\",\"exponential\"):5,\n",
    "             (\"exponential\",\"slow\"):6,\n",
    "             (\"slow\",\"slow\"):7,\n",
    "             (\"exponential\",\"fast\"):8,\n",
    "\n",
    "             # curves without data\n",
    "             (None,\"exponential\"):9,\n",
    "             (None,\"fast\"):9,\n",
    "             (\"fast\",None):9,\n",
    "             None:9}\n",
    "    \n",
    "def to_bfactor(pdb_file,out_file,to_write):\n",
    "\n",
    "    out = []\n",
    "    with open(pdb_file,\"r\") as f:\n",
    "        for line in f:\n",
    "            if line[:4] == \"ATOM\":\n",
    "                r = int(line[22:26])\n",
    "                try:\n",
    "                    number = to_write[r]\n",
    "                except KeyError:\n",
    "                    number = TO_NUMBER[None]\n",
    "\n",
    "                out.append(\"{}{:6.2f}{}\".format(line[:60],number,line[66:]))\n",
    "            else:\n",
    "                out.append(line)\n",
    "\n",
    "    f = open(out_file,\"w\")\n",
    "    f.write(\"\".join(out))\n",
    "    f.close()\n",
    "                \n",
    "a9 = {}\n",
    "m63f = {}\n",
    "compare = {}\n",
    "for i in range(len(df)):\n",
    "\n",
    "    row = df.iloc[i]\n",
    "    A9_type = row.A9_type\n",
    "    M63F_type = row.M63F_type\n",
    "\n",
    "    a9[row.residue] = TO_NUMBER[A9_type]\n",
    "    m63f[row.residue] = TO_NUMBER[M63F_type]\n",
    "    compare[row.residue] = TO_NUMBER[(A9_type,M63F_type)]\n",
    "\n",
    "to_bfactor(\"structure/1irj.pdb\",\"structure/1irj_with-exchange_a9.pdb\",a9)\n",
    "to_bfactor(\"structure/1irj.pdb\",\"structure/1irj_with-exchange_m63f.pdb\",m63f)\n",
    "to_bfactor(\"structure/1irj.pdb\",\"structure/1irj_with-exchange_diff.pdb\",compare)\n",
    "                                  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate exchange vs. residue plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(15,2.5))\n",
    "\n",
    "all_dG = [v for v in -0.001987*298*np.log(df.A9_rate) if not np.isinf(v)]\n",
    "all_dG.extend([v for v in -0.001987*298*np.log(df.A9_rate) if not np.isinf(v)])\n",
    "all_dG = np.array(all_dG)\n",
    "all_dG = all_dG[np.logical_not(np.isnan(all_dG))]\n",
    "\n",
    "min_dG = np.floor(np.min(all_dG))\n",
    "max_dG = np.ceil(np.max(all_dG))\n",
    "\n",
    "\n",
    "span = (max_dG - min_dG)\n",
    "\n",
    "fast_line = min_dG - 0.5\n",
    "slow_line = max_dG + 0.5\n",
    "\n",
    "mapper = {\"fast\":fast_line,\n",
    "          \"slow\":slow_line}\n",
    "\n",
    "colors = {\"fast\":\"firebrick\",\n",
    "          \"exponential\":\"teal\",\n",
    "          \"slow\":\"darkblue\"}\n",
    "\n",
    "ax.plot((-1,119),(min_dG,min_dG),\"--\",color=\"gray\")\n",
    "ax.plot((-1,119),(max_dG,max_dG),\"--\",color=\"gray\")\n",
    "\n",
    "for i in range(len(df)):\n",
    "    row = df.iloc[i]\n",
    "    \n",
    "    resid = row.residue\n",
    "    a9 = row.A9_type\n",
    "    m63f = row.M63F_type\n",
    "    \n",
    "    if a9 == \"exponential\":\n",
    "        a9_pos = -0.001987*298*np.log(row.A9_rate)\n",
    "    else:\n",
    "        try:\n",
    "            a9_pos = mapper[a9]\n",
    "        except KeyError:\n",
    "            a9 = None\n",
    "            a9_pos = np.nan\n",
    "            \n",
    "    if a9 is not None:\n",
    "        ax.scatter([resid],[a9_pos],\n",
    "                    s=80,facecolors=\"none\",\n",
    "                    edgecolors=colors[a9])\n",
    "            \n",
    "    if m63f == \"exponential\":\n",
    "        m63f_pos = -0.001987*298*np.log(row.M63F_rate)\n",
    "    else:\n",
    "        try:\n",
    "            m63f_pos = mapper[m63f]\n",
    "        except KeyError:\n",
    "            m63f = None\n",
    "            m63f_pos = np.nan\n",
    "            \n",
    "    if m63f is not None:\n",
    "        ax.scatter([resid],[m63f_pos],\n",
    "                    s=80,facecolors=colors[m63f],\n",
    "                    edgecolors=colors[m63f])\n",
    "\n",
    "    \n",
    "    # Drawing arrow\n",
    "    if a9 and m63f:\n",
    "        if m63f_pos > a9_pos:\n",
    "            color = \"blue\"\n",
    "        elif a9_pos > m63f_pos:\n",
    "            color = \"red\"\n",
    "        else:\n",
    "            # If they are the same, do not draw arrow\n",
    "            color = None\n",
    "            continue\n",
    "        \n",
    "        if color:\n",
    "            \n",
    "            dy =  m63f_pos-a9_pos - 0.50\n",
    "            if dy < 0:\n",
    "                dy = 0\n",
    "                \n",
    "            if m63f_pos - a9_pos < 0:\n",
    "                dy = m63f_pos - a9_pos + 0.50\n",
    "                if dy > 0:\n",
    "                    dy = 0\n",
    "            \n",
    "            ax.arrow(resid,a9_pos,\n",
    "                     0,dy,\n",
    "                     color=color,\n",
    "                     lw=1,\n",
    "                     head_width=1,\n",
    "                     head_length=0.25)\n",
    "    \n",
    "fig.savefig(\"exchange-vs-residue-plot.pdf\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A9 and M63F class contingency table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dG_list = []\n",
    "possible = [\"fast\",\"exponential\",\"slow\"]\n",
    "for p1 in possible:\n",
    "    for p2 in possible:\n",
    "    \n",
    "        a = df[np.logical_and(df.A9_type == p1,df.M63F_type == p2)]\n",
    "\n",
    "        if p1 == \"exponential\" and p2 == \"exponential\":\n",
    "            dG_list.append(-0.001987*298*np.log(a.M63F_rate/a.A9_rate))\n",
    "            \n",
    "\n",
    "        print(p1,p2,len(a))\n",
    "    \n",
    "        \n",
    "    \n",
    "print(\"ddG:\",np.mean(dG_list),\"+/-\",np.std(dG_list))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
